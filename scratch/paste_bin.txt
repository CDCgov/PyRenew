 seeding ("initialization" in MSR lingo):

 no renewal process, no need for a defined R(t)

pre-observation: renewal process in progress but we set observed hosps to zero and set alpha ~= 0 to allow the process to "warm up"


observation: renewal process in progress, alpha â‰  0, and observed hosps have values, so they are used for inference




REMOVE I0 initialization, co-code (1)

self.I0 = InfectionInitializationProcess(
            "I0_initialization",
            I_pre_init_rv=DistributionalRV(
                name="I0",
                dist=dist.LogNormal(
                    loc=jnp.log(100), scale=jnp.log(1.75)),
            ),  # confirm: need to change from tutoral values
            infection_init_method=InitializeInfectionsExponentialGrowth(
                n_timepoints=self.n_pre_observation_days,
                rate=DeterministicVariable(
                    name="rate", value=0.05),
            ),  # update: initialize infection vector w/ exp DISTRIBUTED vector
            t_unit=1,
        )


REMOVE run method, co-code (1)

def run(self, **kwargs):  # numpydoc ignore=GL08
        kernel = numpyro.infer.NUTS(
            model=self.model,
            step_size=self.adapt_delta,
            max_tree_depth=self.max_treedepth,
        )
        mcmc = numpyro.infer.MCMC(
            sampler=kernel,
            num_warmup=self.n_warmup,
            num_samples=self.n_iter,
            num_chains=self.n_chains,
        )
        mcmc.run(
            rng_key=jax.random.PRNGKey(self.seed),
            data_observed_hosp_admissions=self.data_observed_hosp_admissions,
        )
        mcmc.print_summary()
        self.mcmc = mcmc
        # update: defer to metaclass for model + run
        # update: represent data_observed_hosp_admissions as an attribute,
        # but not as an instance attributes; pass this to the.
        # "a model should have as few numbers as it in possible"
        # "any numbers that the model sees should be passed in at run time"
        # "config should be seen at run time"


REMOVE _init_observation_component, co-code (1)


def _init_observation_component(self):  # numpydoc ignore=GL08
        # update: connect w/ alpha
        # update: combine w/ alpha as a class
        # update this; remove extraneous; rename; add reciprocal dispersion
        nb_conc_rv = TransformedRandomVariable(
            "concentration",
            base_rv=DistributionalRV(
                name="concentration_raw",
                dist=dist.Normal(0, 1)
            ),
            transforms=t.ScaledLogitTransform(x_max=self.max_rt),
        )
        self.admissions = NegativeBinomialObservation(
            name="hospital_admissions", concentration_rv=nb_conc_rv
        )

REMOVE _init_alpha, co-code (1)

def _init_alpha_t(self):  # numpydoc ignore=GL08
        predictor_values = self.predictors
        alpha_intercept_prior = dist.Normal(
            self.ihr_intercept_prior_mode, self.ihr_intercept_prior_scale
        )
        day_of_week_priors = dist.Normal(0, 0.25).expand([6])
        holiday_prior = dist.Normal(
            self.holiday_eff_prior_mode, self.holiday_eff_prior_scale
        ).expand([1])
        post_holiday_prior = dist.Normal(
            self.post_holiday_eff_prior_mode, self.post_holiday_eff_prior_scale
        ).expand([1])
        pre_observation_prior = dist.Normal(
            self.non_obs_effect_prior_mode, self.non_obs_effect_prior_mode
        ).expand([1])
        all_coefficient_priors = jnp.concatenate(
            [
                day_of_week_priors,
                holiday_prior,
                post_holiday_prior,
                pre_observation_prior,
            ]
        )
        self.alpha_process = GLMPrediction(
            name="alpha_t",
            fixed_predictor_values=predictor_values,
            intercept_prior=alpha_intercept_prior,
            coefficient_priors=all_coefficient_priors,
            transform=t.ScaledLogitTransform(x_max=self.max_rt),
        )  # update: make this into its own class


REMOVED CFAEPIM_Rt, co-code (1)

class CFAEPIM_Rt(RandomVariable):  # numpydoc ignore=GL08
    def __init__(
        self, intercept_RW_prior, max_rt, gamma_RW_prior, gamma_RW_prior_scale
    ):  # numpydoc ignore=GL08
        self.intercept_RW_prior = intercept_RW_prior
        self.max_rt = max_rt
        self.gamma_RW_prior = gamma_RW_prior
        self.gamma_RW_prior_scale = gamma_RW_prior_scale

    @staticmethod
    def validate() -> None:  # numpydoc ignore=GL08
        pass

    def sample(self, n_steps: int, **kwargs) -> tuple:  # numpydoc ignore=GL08
        glm = GLMPrediction(
            name="CFAEPIM_Rt_GLM",
            fixed_predictor_values=jnp.ones((n_steps, 1)),  # intercept & RW
            intercept_prior=self.intercept_RW_prior,
            coefficient_priors=self.gamma_RW_prior,
            transform=t.ScaledLogitTransform(x_max=self.max_rt),
        )
        # update: Epidemia does this all as GLM under the hood,
        # but epimlight model just has Rt intercept & random walk
        # update: intercept can just be part of RtWalk, simple random
        # walk can be transformed using scaled logit, init_rv = intercept
        # prior, sd_wt (as you've done). These needs to be broadcast from
        # weekly to daily.
        eta_samples = glm.sample()
        sd_wt = numpyro.sample("Wt_rw_sd", dist.gamma_RW_prior_scale)
        wt_rv = SimpleRandomWalkProcess(
            name="Wt",
            step_rv=DistributionalRV(
                name="rw_step_rv",
                dist=dist.Normal(0, sd_wt),  # confirm: should I reuse
                reparam=LocScaleReparam(0),  # confirm: thoughts on this?
            ),
            init_rv=DistributionalRV(
                name="init_Wt_rv",
                dist=dist.Normal(
                    0, 1
                ),  # confirm: not sure what else to put here
            ),
        )
        wt_samples = wt_rv.sample(n_steps=n_steps, **kwargs)
        rt_samples = eta_samples["prediction"] + wt_samples[0].value
        # update: don't want scaled logit twice, remove GLM section;
        transformed_rt_samples = t.ScaledLogitTransform(x_max=self.max_rt)(
            rt_samples
        )
        return transformed_rt_samples

    # update: broadcast weekly to daily
